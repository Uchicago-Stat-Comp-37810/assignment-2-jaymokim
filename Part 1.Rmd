---
title: "Part 1"
author: "Jaymo Kim"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
source("summaryfunc.R")
```

```{r}
# Creating Test Data
trueA <- 5    # slope
trueB <- 0    # intercept
trueSd <- 10    # true sd
sampleSize <- 31    # sample size
```

```{r}
# create independent x-values 
# x-values with a size of a sample size
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)    

# create dependent values according to ax + b + N(0,sd)
# y-values according to the model
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)    

# A scatterplot of the created x-values and dependent values according to the model.
plot(x,y, main="Test Data")    
```

```{r}
# Example: plot the likelihood profile of the slope a
# a sum of likelihoods for different values of slope
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )

# plot of the likelihood profile of the slope a
plot (seq(3, 7, by=.05), slopelikelihoods , type="l",
      xlab = "values of slope parameter a", ylab = "Log likelihood")    
```

```{r}
# setting the start value
startvalue = c(4,0,10)
# getting the chain by starting with the startvalue and iterating for 10000 times
chain = run_metropolis_MCMC(startvalue, 10000)

burnIn = 5000    # number of burning iterations
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))    # Accepance rate

summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)

# for comparison:
summary(lm(y~x))    # comparing the methodf of MCMC with the method of linear regression
```

```{r}
set.seed(1023)
# compare_outcomes function
compare_outcomes <- function(n) {
    alpha = runif(10, min=0, max=10)
    beta = rnorm(10, sd = 5)
    sigma = runif(10, min=0, max=30)
    for(i in 1:10) {
        ch <- run_metropolis_MCMC(startvalue = c(alpha[i], beta[i], sigma[i]),
                                  iterations = n)
        print(c(mean(ch[, 1]), sd(ch[, 1])))
    }
}
# mean and sd for a, iteration(n) = 1,000
compare_outcomes(n = 1000)

# mean and sd for a, iteration(n) = 10,000
compare_outcomes(n = 10000)

# mean and sd for a, iteration(n) = 100,000
compare_outcomes(n = 100000)
```

Based on the outcome of compare_outcome function, we can observe that there are subtle differences in accuracy of this algorithm in finding $a$ for different number of iterations. 

For the outcome of this algorithm with iteration = 1,000, the mean and the standard deviation of $a$ fluctuate: the mean of $a$ ranges from 4.43 to 5.17 and the standard deviation of $a$ ranges from 0.20 to 1.18. 

For iteration = 10,000, the mean and the standard deviation of $a$ fluctuate less. The mean of $a$ ranges from 4.73 to 4.86 and the standard deviation of $a$ ranges from 0.21 to 0.59.

Lastly, for iteration = 100,000, the mean and the standard deviation of $a$ is most consistent. The mean of $a$ only ranges from 4.76 to 4.77 and the standard deviation of $a$ only ranges from 0.20 to 0.22.

In summary, the algorithm gets more accurate for the mean and the standard deviation of $a$ are more consistent as the number of iteration increases. Therefore, we can conclude that in order for the algorithm to be as accurate, and thus close to the linear regression, as possible, we would need a large number of iteration.

