# Creating Test Data
trueA <- 5
trueB <- 0
trueSd <- 10
sampleSize <- 31
# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)
plot(x,y, main="Test Data")
# Deriving the likelihood funcion from the model
likelihood <- function(param){
a = param[1]
b = param[2]
sd = param[3]
pred = a*x + b
singlelikelihoods = dnorm(y, mean = pred, sd = sd, log = T)
sumll = sum(singlelikelihoods)
return(sumll)
}
# Example: plot the likelihood profile of the slope a
slopevalues <- function(x){return(likelihood(c(x, trueB, trueSd)))}
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")
# Prior distribution
prior <- function(param){
a = param[1]
b = param[2]
sd = param[3]
aprior = dunif(a, min=0, max=10, log = T)
bprior = dnorm(b, sd = 5, log = T)
sdprior = dunif(sd, min=0, max=30, log = T)
return(aprior+bprior+sdprior)
}
# Posterior distribution
posterior <- function(param){
return (likelihood(param) + prior(param))
}
# Metropolis algorithm
proposalfunction <- function(param){
return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3)))
}
run_metropolis_MCMC <- function(startvalue, iterations){
chain = array(dim = c(iterations+1,3))
chain[1,] = startvalue
for (i in 1:iterations){
proposal = proposalfunction(chain[i,])
probab = exp(posterior(proposal) - posterior(chain[i,]))
if (runif(1) < probab){
chain[i+1,] = proposal
}else{
chain[i+1,] = chain[i,]
}
}
return(chain)
}
startvalue = c(4,0,10)
chain = run_metropolis_MCMC(startvalue, 10000)
burnIn = 5000
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
# Summary
par(mfrow = c(2,3))
hist(chain[-(1:burnIn),1],nclass=30, , main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = trueA, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of b", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]))
abline(v = trueB, col="red" )
hist(chain[-(1:burnIn),3],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),3]) )
abline(v = trueSd, col="red" )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
abline(h = trueA, col="red" )
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of b", )
abline(h = trueB, col="red" )
plot(chain[-(1:burnIn),3], type = "l", xlab="True value = red line" , main = "Chain values of sd", )
abline(h = trueSd, col="red" )
# for comparison:
summary(lm(y~x))
1 - qnorm(2.0702)
pnorm(2.0702)
1-pnorm(2.0702)
source('~/.active-rstudio-document', echo=TRUE)
# Creating Test Data
trueA <- 5
trueB <- 0
trueSd <- 10
sampleSize <- 31
# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)
plot(x,y, main="Test Data")
# Deriving the likelihood funcion from the model
likelihood <- function(param){
a = param[1]
b = param[2]
sd = param[3]
pred = a*x + b
singlelikelihoods = dnorm(y, mean = pred, sd = sd, log = T)
sumll = sum(singlelikelihoods)
return(sumll)
}
# Example: plot the likelihood profile of the slope a
slopevalues <- function(x){return(likelihood(c(x, trueB, trueSd)))}
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")
# Prior distribution
prior <- function(param){
a = param[1]
b = param[2]
sd = param[3]
aprior = dunif(a, min=0, max=10, log = T)
bprior = dnorm(b, sd = 5, log = T)
sdprior = dunif(sd, min=0, max=30, log = T)
return(aprior+bprior+sdprior)
}
# Posterior distribution
posterior <- function(param){
return (likelihood(param) + prior(param))
}
# Metropolis algorithm
proposalfunction <- function(param){
return(rnorm(3,mean = param, sd= c(0.1,0.5,0.3)))
}
run_metropolis_MCMC <- function(startvalue, iterations){
chain = array(dim = c(iterations+1,3))
chain[1,] = startvalue
for (i in 1:iterations){
proposal = proposalfunction(chain[i,])
probab = exp(posterior(proposal) - posterior(chain[i,]))
if (runif(1) < probab){
chain[i+1,] = proposal
}else{
chain[i+1,] = chain[i,]
}
}
return(chain)
}
startvalue = c(4,0,10)
chain = run_metropolis_MCMC(startvalue, 10000)
burnIn = 5000
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))
# Summary
par(mfrow = c(2,3))
hist(chain[-(1:burnIn),1],nclass=30, , main="Posterior of a", xlab="True value = red line" )
abline(v = mean(chain[-(1:burnIn),1]))
abline(v = trueA, col="red" )
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of b", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),2]))
abline(v = trueB, col="red" )
hist(chain[-(1:burnIn),3],nclass=30, main="Posterior of sd", xlab="True value = red line")
abline(v = mean(chain[-(1:burnIn),3]) )
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
abline(h = trueA, col="red" )
abline(v = trueSd, col="red" )
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of b", )
abline(h = trueB, col="red" )
plot(chain[-(1:burnIn),3], type = "l", xlab="True value = red line" , main = "Chain values of sd", )
abline(h = trueSd, col="red" )
# for comparison:
summary(lm(y~x))
par(mfrow=x(1,1))
par(mfrow=c(1,1))
plot(x,y, main="Test Data")
# Example: plot the likelihood profile of the slope a
slopevalues <- function(x){return(likelihood(c(x, trueB, trueSd)))}
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")
proposalfunction(c(4,0,10))
acceptance
duplicated(chain[1,])
duplicated(chain[-(1:burnIn),])
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )
# for comparison:
summary(lm(y~x))
summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)
# Summary
summaryfunc <- function(chain, burnIn, trueA, trueB, trueSd) {
par(mfrow = c(2,3))    # dividing the plotting screen to 2 rows and 3 columns
hist(chain[-(1:burnIn),1],nclass=30, , main="Posterior of a", xlab="True value = red line" )    # histogram of posterior of a (slope)
abline(v = mean(chain[-(1:burnIn),1]))    # making a line indicating the mean value of a
abline(v = trueA, col="red" )    # making a red line indicating the true value of a
hist(chain[-(1:burnIn),2],nclass=30, main="Posterior of b", xlab="True value = red line")    # histogram of posterior of b (intercept)
abline(v = mean(chain[-(1:burnIn),2]))    # making a line indicating the mean value of b
abline(v = trueB, col="red" )    # making a red line indicating the true value of b
hist(chain[-(1:burnIn),3],nclass=30, main="Posterior of sd", xlab="True value = red line")    # histogram of posterior of sd
abline(v = mean(chain[-(1:burnIn),3]) )    # making a line indicating the mean value of sd
abline(v = trueSd, col="red" )    # making a red line indicating the true value of sd
plot(chain[-(1:burnIn),1], type = "l", xlab="True value = red line" , main = "Chain values of a", )    # plot showing the chain values of a (slope)
abline(h = trueA, col="red" )    # making a red line indicating the true value of a
plot(chain[-(1:burnIn),2], type = "l", xlab="True value = red line" , main = "Chain values of b", )    # plot showing the chain values of b (intercept)
abline(h = trueB, col="red" )    # making a red line indicating the true value of b
plot(chain[-(1:burnIn),3], type = "l", xlab="True value = red line" , main = "Chain values of sd", )    # plot showing the chain values of sd
abline(h = trueSd, col="red" )    # making a red line indicating the true value of sd
}
summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)
summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)
source('~/GitHub/assignment-2-jaymokim/Part 1.R', echo=TRUE)
?source
source(likelihood)
source(likelihood.R)
source(likelihood)
cd
source(likelihood.R)
source("likelihood.R")
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
setwd("~/GitHub/assignment-2-jaymokim")
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
source("summaryfunc.R")
# Creating Test Data
trueA <- 5    # slope
trueB <- 0    # intercept
trueSd <- 10    # true sd
sampleSize <- 31    # sample size
# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)    # x-values with a size of a sample size
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)    # y-values according to the model
plot(x,y, main="Test Data")    # A scatterplot of the created x-values and dependent values according to the model.
# Example: plot the likelihood profile of the slope a
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )    # a sum of likelihoods for different values of slope
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")    # plot of the likelihood profile of the slope a
startvalue = c(4,0,10)    # setting the start value
chain = run_metropolis_MCMC(startvalue, 10000)    # getting the chain by starting with the startvalue and iterating for 10000 times
burnIn = 5000    # number of burning iterations
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))    # Accepance rate
summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)
# for comparison:
summary(lm(y~x))    # comparing the methodf of MCMC with the method of linear regression
par(mfrow=c(1,1))
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
source("summaryfunc.R")
# Creating Test Data
trueA <- 5    # slope
trueB <- 0    # intercept
trueSd <- 10    # true sd
sampleSize <- 31    # sample size
# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)    # x-values with a size of a sample size
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)    # y-values according to the model
plot(x,y, main="Test Data")    # A scatterplot of the created x-values and dependent values according to the model.
# Example: plot the likelihood profile of the slope a
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )    # a sum of likelihoods for different values of slope
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")    # plot of the likelihood profile of the slope a
startvalue = c(4,0,10)    # setting the start value
chain = run_metropolis_MCMC(startvalue, 10000)    # getting the chain by starting with the startvalue and iterating for 10000 times
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
source("summaryfunc.R")
# Creating Test Data
trueA <- 5    # slope
trueB <- 0    # intercept
trueSd <- 10    # true sd
sampleSize <- 31    # sample size
# create independent x-values
x <- (-(sampleSize-1)/2):((sampleSize-1)/2)    # x-values with a size of a sample size
# create dependent values according to ax + b + N(0,sd)
y <-  trueA * x + trueB + rnorm(n=sampleSize,mean=0,sd=trueSd)    # y-values according to the model
plot(x,y, main="Test Data")    # A scatterplot of the created x-values and dependent values according to the model.
# Example: plot the likelihood profile of the slope a
slopelikelihoods <- lapply(seq(3, 7, by=.05), slopevalues )    # a sum of likelihoods for different values of slope
plot (seq(3, 7, by=.05), slopelikelihoods , type="l", xlab = "values of slope parameter a", ylab = "Log likelihood")    # plot of the likelihood profile of the slope a
startvalue = c(4,0,10)    # setting the start value
chain = run_metropolis_MCMC(startvalue, 10000)    # getting the chain by starting with the startvalue and iterating for 10000 times
burnIn = 5000    # number of burning iterations
acceptance = 1-mean(duplicated(chain[-(1:burnIn),]))    # Accepance rate
summaryfunc(chain = chain, burnIn = burnIn, trueA = trueA, trueB = trueB, trueSd = trueSd)
# for comparison:
summary(lm(y~x))    # comparing the methodf of MCMC with the method of linear regression
dim(chain)
mean(chain[,1])
sd(chain[,1])
# compare_outcomes function
compare_outcomes <- function(n) {
for(i in 1:10) {
a = runif(1, min=0, max=10, log = T)
b = rnorm(1, sd = 5, log = T)
sd = runif(1, min=0, max=30, log = T)
run_metropolis_MCMC(startvalue = c(a, b, sd), iterations = n)
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
# compare_outcomes function
compare_outcomes <- function(n) {
for(i in 1:10) {
a = runif(1, min=0, max=10)
b = rnorm(1, sd = 5)
sd = runif(1, min=0, max=30)
run_metropolis_MCMC(startvalue = c(a, b, sd), iterations = n)
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
run_metropolis_MCMC(startvalue = c(a[i], b[i], sd[i]), iterations = n)
# compare_outcomes function
compare_outcomes <- function(n) {
for(i in 1:10) {
a = runif(10, min=0, max=10)
b = rnorm(10, sd = 5)
sd = runif(10, min=0, max=30)
run_metropolis_MCMC(startvalue = c(a[i], b[i], sd[i]), iterations = n)
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
head(chain)
# compare_outcomes function
compare_outcomes <- function(n) {
for(i in 1:10) {
a = runif(10, min=0, max=10)
b = rnorm(10, sd = 5)
sd = runif(10, min=0, max=30)
run_metropolis_MCMC(startvalue = c(a[i], b[i], sd[i]), iterations = n)
print(head(chain))
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
sd = runif(10, min=0, max=30)
# compare_outcomes function
compare_outcomes <- function(n) {
a = runif(10, min=0, max=10)
b = rnorm(10, sd = 5)
sd = runif(10, min=0, max=30)
for(i in 1:10) {
run_metropolis_MCMC(startvalue = c(a[i], b[i], sd[i]), iterations = n)
print(head(chain))
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
a = runif(10, min=0, max=10)
b = rnorm(10, sd = 5)
sd = runif(10, min=0, max=30)
a
b
sd
a[1]
# compare_outcomes function
compare_outcomes <- function(n) {
a = runif(10, min=0, max=10)
b = rnorm(10, sd = 5)
sd = runif(10, min=0, max=30)
for(i in 1:10) {
run_metropolis_MCMC(startvalue = c(a[i], b[i], sd[i]), iterations = n)
print(head(chain))
print(c(mean(chain[, 1]), sd(chain[, 1])))
}
}
compare_outcomes(1000)
# compare_outcomes function
compare_outcomes <- function(n) {
alpha = runif(10, min=0, max=10)
beta = rnorm(10, sd = 5)
sigma = runif(10, min=0, max=30)
for(i in 1:10) {
ch <- run_metropolis_MCMC(startvalue = c(alpha[i], beta[i], sigma[i]), iterations = n)
print(head(ch))
print(c(mean(ch[, 1]), sd(ch[, 1])))
}
}
compare_outcomes(1000)
# compare_outcomes function
compare_outcomes <- function(n) {
alpha = runif(10, min=0, max=10)
beta = rnorm(10, sd = 5)
sigma = runif(10, min=0, max=30)
for(i in 1:10) {
ch <- run_metropolis_MCMC(startvalue = c(alpha[i], beta[i], sigma[i]), iterations = n)
print(c(mean(ch[, 1]), sd(ch[, 1])))
}
}
compare_outcomes(1000)
compare_outcomes(10000)
compare_outcomes(10000)
compare_outcomes(100000)
knitr::opts_chunk$set(echo = TRUE)
source("likelihood.R")
source("slopevalues.R")
source("prior.R")
source("posterior.R")
source("proposalfunction.R")
source("run_metropolis_MCMC.R")
source("summaryfunc.R")
# compare_outcomes function
compare_outcomes <- function(n) {
alpha = runif(10, min=0, max=10)
beta = rnorm(10, sd = 5)
sigma = runif(10, min=0, max=30)
for(i in 1:10) {
ch <- run_metropolis_MCMC(startvalue = c(alpha[i], beta[i], sigma[i]), iterations = n)
print(c(mean(ch[, 1]), sd(ch[, 1])))
}
}
compare_outcomes(n = 1000)
compare_outcomes(n = 10000)
compare_outcomes(n = 100000)
set.seed(1023)
# compare_outcomes function
compare_outcomes <- function(n) {
alpha = runif(10, min=0, max=10)
beta = rnorm(10, sd = 5)
sigma = runif(10, min=0, max=30)
for(i in 1:10) {
ch <- run_metropolis_MCMC(startvalue = c(alpha[i], beta[i], sigma[i]), iterations = n)
print(c(mean(ch[, 1]), sd(ch[, 1])))
}
}
# mean and sd for a, iteration(n) = 1,000
compare_outcomes(n = 1000)
# mean and sd for a, iteration(n) = 10,000
compare_outcomes(n = 10000)
# mean and sd for a, iteration(n) = 100,000
compare_outcomes(n = 100000)
knitr::opts_chunk$set(echo = TRUE)
library(faraway)
par(1)
?par()
plot(c(1,2,3,4) ~ c(4,5,6,7))
par(mfrow=c(1,2))
plot(c(1,2,3,4) ~ c(4,5,6,7))
par(1)
plot(c(1,2,3,4) ~ c(4,5,6,7))
layout91
layout(1)
# Part a (check the constant variance assumption for the errors)
par(mfrow=c(1,2))
plot(fitted(g), residuals(g), xlab = "Fitted", ylab = "Residuals")
abline(h = 0)
data("teengamb")
g <- lm(gamble ~ ., data = teengamb)
# Part a (check the constant variance assumption for the errors)
par(mfrow=c(1,2))
plot(fitted(g), residuals(g), xlab = "Fitted", ylab = "Residuals")
abline(h = 0)
plot(fitted(g), residuals(g), xlab = "Fitted", ylab = "Residuals")
abline(h = 0)
library(faraway)
data("teengamb")
g <- lm(gamble ~ ., data = teengamb)
# Part a (check the constant variance assumption for the errors)
par(mfrow=c(1,2))
plot(fitted(g), residuals(g), xlab = "Fitted", ylab = "Residuals")
abline(h = 0)
plot(fitted(g), abs(residuals(g)), xlab = "Fitted", ylab = "|Residuals|")
# Part b (check the normality assumption)
# Part c (check for large leverage points)
# Part d (check for outliers)
# Part e (check for influential points)
# Part f (check for the structure of the relationship between the predictors and the response)
summary(lm(abs(residuals(g)) ~ fitted(g)))
library(faraway)
data("teengamb")
g <- lm(gamble ~ ., data = teengamb)
# Part a (check the constant variance assumption for the errors)
par(mfrow=c(1,2))
plot(fitted(g), residuals(g), xlab = "Fitted", ylab = "Residuals")
abline(h = 0)
plot(fitted(g), abs(residuals(g)), xlab = "Fitted", ylab = "|Residuals|")
summary(lm(abs(residuals(g)) ~ fitted(g)))
# Part b (check the normality assumption)
par(mfrow=c(1,2))
qqnorm(residuals(g), ylab = "Residuals")
qqline(residuals(g))
hist(residuals(g))
# Part b (check the normality assumption)
par(mfrow=c(1,2))
qqnorm(residuals(g), ylab = "Residuals")
qqline(residuals(g))
hist(residuals(g))
shapiro.test(residuals(g))
# Part a
data("sat")
lm(total ~ ., data = sat)
lm(total ~ expend, data = sat)
# Part a
data("sat")
summary(lm(total ~ ., data = sat))
summary(lm(total ~ expend, data = sat))
# Part a
data("sat")
lm(total ~ ., data = sat)
lm(total ~ expend, data = sat)
# Part a
data("sat")
lm(total ~ expend + ratio + salary + takers, data = sat)
lm(total ~ expend, data = sat)
# Part b
summary(lm(total ~ expend + ratio + salary + takers, data = sat))
summary(lm(total ~ takers, data = sat))
